{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+jQKLsvjYMsT24/74mjnv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RyuichiSaito1/covid19-twitter-usa-restoring/blob/main/join_tweets_separated_by_restriction_type.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAveHLQMorp9"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "output_directory = '/content/drive/My Drive/covid-twitter-usa-normal/result/gpt-3.5-turbo/new_york_city/total/'\n",
        "\n",
        "file_count = 0  # Initialize a variable to count the number of files processed\n",
        "\n",
        "# Loop through the files in the specified directory\n",
        "for content in os.listdir('/content/drive/My Drive/covid-twitter-usa-normal/result/gpt-3.5-turbo/new_york_city/1/'):\n",
        "    print(content)\n",
        "\n",
        "    # Read data from three different files\n",
        "    df_1 = pd.read_table('/content/drive/My Drive/covid-twitter-usa-normal/result/gpt-3.5-turbo/new_york_city/1/' + content, names=('tweet_id', 'author_id', 'text', 'score'), dtype='object', engine='python')\n",
        "    df_2 = pd.read_table('/content/drive/My Drive/covid-twitter-usa-normal/result/gpt-3.5-turbo/new_york_city/2/' + content, names=('tweet_id', 'author_id', 'text', 'score'), dtype='object', engine='python')\n",
        "    df_3 = pd.read_table('/content/drive/My Drive/covid-twitter-usa-normal/result/gpt-3.5-turbo/new_york_city/3/' + content, names=('tweet_id', 'author_id', 'text', 'score'), dtype='object', engine='python')\n",
        "\n",
        "    # Concatenate the data from three files\n",
        "    df_total = pd.concat([df_1, df_2, df_3])\n",
        "\n",
        "    # Specify the output path and save the concatenated data\n",
        "    output_path = os.path.join(output_directory, content)\n",
        "    df_total.to_csv(output_path, sep='\\t', index=False, header=False)\n",
        "\n",
        "    file_count += 1  # Increment the count for each processed file\n",
        "\n",
        "# Display the number of files processed at the end\n",
        "print(\"Processed files:\", file_count)"
      ],
      "metadata": {
        "id": "5PEkSlMEoxw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "output_directory = '/content/drive/My Drive/covid-twitter-usa-normal/result/gpt-3.5-turbo/los_angeles/total/'\n",
        "\n",
        "file_count = 0  # Initialize a variable to count the number of files processed\n",
        "\n",
        "# Loop through the files in the specified directory\n",
        "for content in os.listdir('/content/drive/My Drive/covid-twitter-usa-normal/result/gpt-3.5-turbo/los_angeles/1/'):\n",
        "    print(content)\n",
        "\n",
        "    # Read data from three different files\n",
        "    df_1 = pd.read_table('/content/drive/My Drive/covid-twitter-usa-normal/result/gpt-3.5-turbo/los_angeles/1/' + content, names=('tweet_id', 'author_id', 'text', 'score'), dtype='object', engine='python')\n",
        "    df_2 = pd.read_table('/content/drive/My Drive/covid-twitter-usa-normal/result/gpt-3.5-turbo/los_angeles/2/' + content, names=('tweet_id', 'author_id', 'text', 'score'), dtype='object', engine='python')\n",
        "    df_3 = pd.read_table('/content/drive/My Drive/covid-twitter-usa-normal/result/gpt-3.5-turbo/los_angeles/3/' + content, names=('tweet_id', 'author_id', 'text', 'score'), dtype='object', engine='python')\n",
        "\n",
        "    # Concatenate the data from three files\n",
        "    df_total = pd.concat([df_1, df_2, df_3])\n",
        "\n",
        "    # Specify the output path and save the concatenated data\n",
        "    output_path = os.path.join(output_directory, content)\n",
        "    df_total.to_csv(output_path, sep='\\t', index=False, header=False)\n",
        "\n",
        "    file_count += 1  # Increment the count for each processed file\n",
        "\n",
        "# Display the number of files processed at the end\n",
        "print(\"Processed files:\", file_count)"
      ],
      "metadata": {
        "id": "Uw0nJDuiq_vM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "output_directory = '/content/drive/My Drive/covid-twitter-usa-normal/result/gpt-3.5-turbo/chicago/total/'\n",
        "\n",
        "file_count = 0  # Initialize a variable to count the number of files processed\n",
        "\n",
        "# Loop through the files in the specified directory\n",
        "for content in os.listdir('/content/drive/My Drive/covid-twitter-usa-normal/result/gpt-3.5-turbo/chicago/1/'):\n",
        "    print(content)\n",
        "\n",
        "    # Read data from three different files\n",
        "    df_1 = pd.read_table('/content/drive/My Drive/covid-twitter-usa-normal/result/gpt-3.5-turbo/chicago/1/' + content, names=('tweet_id', 'author_id', 'text', 'score'), dtype='object', engine='python')\n",
        "    df_2 = pd.read_table('/content/drive/My Drive/covid-twitter-usa-normal/result/gpt-3.5-turbo/chicago/2/' + content, names=('tweet_id', 'author_id', 'text', 'score'), dtype='object', engine='python')\n",
        "    df_3 = pd.read_table('/content/drive/My Drive/covid-twitter-usa-normal/result/gpt-3.5-turbo/chicago/3/' + content, names=('tweet_id', 'author_id', 'text', 'score'), dtype='object', engine='python')\n",
        "\n",
        "    # Concatenate the data from three files\n",
        "    df_total = pd.concat([df_1, df_2, df_3])\n",
        "\n",
        "    # Specify the output path and save the concatenated data\n",
        "    output_path = os.path.join(output_directory, content)\n",
        "    df_total.to_csv(output_path, sep='\\t', index=False, header=False)\n",
        "\n",
        "    file_count += 1  # Increment the count for each processed file\n",
        "\n",
        "# Display the number of files processed at the end\n",
        "print(\"Processed files:\", file_count)"
      ],
      "metadata": {
        "id": "iDWT6l7Lt_Ys"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}