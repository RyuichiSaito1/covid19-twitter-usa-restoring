{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMiOfYyU30AnT/VGsgvzL8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RyuichiSaito1/covid19-twitter-usa-restoring/blob/main/full_archive_search_nyc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgRVjrdIXyvm"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stay-at-Home-Ordered\n",
        "\n",
        "import datetime\n",
        "\n",
        "# start_date = datetime.date(2021, 10, 31)\n",
        "start_date = datetime.date(2021, 11, 21)\n",
        "# end_date = datetime.date(2022, 12, 31)\n",
        "end_date = datetime.date(2022, 1, 1)\n",
        "\n",
        "city = 'new york'\n",
        "\n",
        "search_strings = ['\"go out\"', '\"going out\"',\n",
        "                  '\"go to work\"', '\"going to work\"',\n",
        "                  '\"to my office\"', '\"to school\"',\n",
        "                  '\"to college\"', '\"attend the class\"',\n",
        "                  '\"by train\"', '\"by bus\"']\n",
        "\n",
        "directory1 = '/content/drive/My Drive/covid-twitter-usa-normal/data/collection_data/new_york_city/1/1/'\n",
        "directory2 = '/content/drive/My Drive/covid-twitter-usa-normal/data/collection_data/new_york_city/1/2/'\n"
      ],
      "metadata": {
        "id": "8bgjFJ5dbG5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Restrictions-on-Gatherings\n",
        "\n",
        "import datetime\n",
        "\n",
        "start_date = datetime.date(2021, 10, 31)\n",
        "end_date = datetime.date(2022, 12, 31)\n",
        "\n",
        "city = 'new york'\n",
        "\n",
        "search_strings = ['\"to the movies\"', '\"to the theater\"',\n",
        "                  '\"see a play\"', '\"to a concert\"',\n",
        "                  '\"to the concert\"', '\"to the gig\"',\n",
        "                  '\"to the museum\"', '\"to the planetarium\"',\n",
        "                  '\"see the game\"', '\"to the stadium\"',\n",
        "                  '\"gathering\"', '\"to a club\"',\n",
        "                  '\"to the amusement\"', '\"go bowling\"',\n",
        "                  '\"to casinos\"', '\"to the racetrack\"',\n",
        "                  '\"to the bingo\"', '\"to an arcade\"',\n",
        "                  '\"to the arcade\"', '\"to church\"',\n",
        "                  '\"wedding\"', '\"on a date\"',\n",
        "                  '\"to a party\"', '\"to the party\"',\n",
        "                  '\"have a party\"', '\"to bbq\"',\n",
        "                  '\"hava a bbq\"', '\"for a drink\"',\n",
        "                  '\"to a bar\"', '\"get-together\"',\n",
        "                  '\"drinking party\"', '\"to a restaurant\"',\n",
        "                  '\"eat out\"', '\"eating out\"',\n",
        "                  '\"to a cafe\"', '\"meetup\"',\n",
        "                  '\"go shopping\"', '\"going shopping\"',\n",
        "                  '\"to the mall\"', '\"to the salon\"',\n",
        "                  '\"get a haircut\"', '\"to the gym\"',\n",
        "                  '\"go swimming\"', '\"to a spa\"',\n",
        "                  '\"to a spa\"', '\"to yoga\"',\n",
        "                  '\"to massage\"', '\"to the auditorium\"']\n",
        "\n",
        "directory1 = '/content/drive/My Drive/covid-twitter-usa-normal/data/collection_data/new_york_city/2/1/'\n",
        "directory2 = '/content/drive/My Drive/covid-twitter-usa-normal/data/collection_data/new_york_city/2/2/'"
      ],
      "metadata": {
        "id": "1MeyIu_CKrwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Travel-Restrictions\n",
        "\n",
        "import datetime\n",
        "\n",
        "start_date = datetime.date(2021, 10, 31)\n",
        "end_date = datetime.date(2022, 12, 31)\n",
        "\n",
        "city = 'new york'\n",
        "\n",
        "search_strings = ['\"travel\"', '\"traveling\"',\n",
        "                  '\"on a trip\"', '\"fly to\"',\n",
        "                  '\"by plane\"', '\"visit\"',\n",
        "                  '\"to my hometown\"']\n",
        "\n",
        "directory1 = '/content/drive/My Drive/covid-twitter-usa-normal/data/collection_data/new_york_city/3/1/'\n",
        "directory2 = '/content/drive/My Drive/covid-twitter-usa-normal/data/collection_data/new_york_city/3/2/'\n"
      ],
      "metadata": {
        "id": "udVCLDuHRZTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://towardsdatascience.com/basic-tweet-preprocessing-in-python-efd8360d529e\n",
        "\n",
        "from datetime import timedelta\n",
        "import time\n",
        "import requests\n",
        "import os\n",
        "import json\n",
        "import pandas\n",
        "import re\n",
        "\n",
        "def replace_number_to_zero(text):\n",
        "    changed_text = re.sub(r'[0-9]+', \"0\", text)\n",
        "    return changed_text\n",
        "\n",
        "def date_range(start, stop, step = timedelta(1)):\n",
        "    current = start\n",
        "    while current <= stop:\n",
        "        yield current\n",
        "        current += step\n",
        "\n",
        "def create_headers(bearer_token):\n",
        "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
        "    return headers\n",
        "\n",
        "def connect_to_endpoint(url, headers, params):\n",
        "    response = requests.request(\"GET\", search_url, headers=headers, params=params)\n",
        "    print(response.status_code)\n",
        "    if response.status_code != 200:\n",
        "        raise Exception(response.status_code, response.text)\n",
        "    return response.json()\n",
        "\n",
        "bearer_token = \"AAAAAAAAAAAAAAAAAAAAABeVOwEAAAAAjo5fJzFQCqV1bkwOCT89XAIPtqE%3DqcBXeNvTsRnR7zvitW2R0nazcHF230wtCKSghdujOIovWZ9C93\"\n",
        "\n",
        "search_url = \"https://api.twitter.com/2/tweets/search/all\"\n",
        "\n",
        "def main():\n",
        "\n",
        "    columns = ['author_id', 'created_at','id', 'text', 'geo']\n",
        "    df = pandas.DataFrame(columns=columns)\n",
        "\n",
        "    columns2 = ['id', 'name','username']\n",
        "    df2 = pandas.DataFrame(columns=columns2)\n",
        "\n",
        "    headers = create_headers(bearer_token)\n",
        "\n",
        "    # Repeat for dates\n",
        "    i = 0\n",
        "    for date in date_range(start_date, end_date):\n",
        "\n",
        "      # Search Block\n",
        "      search_date = date.strftime('%Y-%m-%d')\n",
        "      from_date = search_date + 'T00:00:01Z'\n",
        "      to_date =search_date + 'T23:59:59Z'\n",
        "\n",
        "      query_params = \"\"\n",
        "\n",
        "      for j in range(0, len(search_strings), 2):\n",
        "\n",
        "        if j + 1 < len(search_strings):\n",
        "          query = f\"({search_strings[j]} OR {search_strings[j+1]}) -is:retweet point_radius:[-74.005880 40.712791 25mi] lang:en\"\n",
        "        else:\n",
        "          query = f\"{search_strings[j]} -is:retweet point_radius:[-74.005880 40.712791 25mi] lang:en\"\n",
        "\n",
        "        query_params = {\n",
        "          'query': query,\n",
        "          'start_time': from_date,\n",
        "          'end_time': to_date,\n",
        "          'place.fields': 'geo',\n",
        "          'tweet.fields': 'author_id,created_at,geo',\n",
        "          'expansions': 'author_id',\n",
        "          'max_results': '500'}  # between 10 and 500\n",
        "        print(query_params)\n",
        "\n",
        "        json_response = connect_to_endpoint(search_url, headers, query_params)\n",
        "        print(json.dumps(json_response, indent=4, sort_keys=True))\n",
        "\n",
        "        print('Wait 8 seconds')\n",
        "        time.sleep(8)\n",
        "\n",
        "        if json_response['meta']['result_count'] != 0:\n",
        "          # continue\n",
        "\n",
        "          # Output Block\n",
        "          # Repeat for number of acquisitions\n",
        "          for tweet in json_response['data']:\n",
        "\n",
        "            author_id = tweet['author_id']\n",
        "            created_at = tweet['created_at']\n",
        "            id = tweet['id']\n",
        "            text = tweet['text']\n",
        "            try:\n",
        "              geo = tweet['geo']\n",
        "            except KeyError:\n",
        "              geo =''\n",
        "            concat_list = [author_id, created_at, id, text, geo]\n",
        "            df_next = pandas.DataFrame([concat_list], columns=columns)\n",
        "            # df = df.concat(df_next)\n",
        "            df = pandas.concat([df, df_next])\n",
        "\n",
        "          # Repeat for number of acquisitions\n",
        "          for tweet in json_response['includes']['users']:\n",
        "\n",
        "            id = tweet['id']\n",
        "            user = tweet['name']\n",
        "            username = tweet['username']\n",
        "            concat_list = [id, user, username]\n",
        "            df_next = pandas.DataFrame([concat_list], columns=columns2)\n",
        "            # df2 = df2.concat(df_next)\n",
        "            df2 = pandas.concat([df2, df_next])\n",
        "\n",
        "      i += 1\n",
        "\n",
        "      if i == 7:\n",
        "        # Preprocessing\n",
        "        df = df.replace('(https?|ftp)(:\\/\\/[-_\\.!~*\\'()a-zA-Z0-9;\\/?:\\@&=\\+$,%#]+)', '', regex=True)\n",
        "        df = df.replace('(@[-_\\.!~*\\'()a-zA-Z0-9;\\/?:\\@&=\\+$,%#]+)', '', regex=True)\n",
        "        df = df.replace('(#[-_\\.!~*\\'()a-zA-Z0-9;\\/?:\\@&=\\+$,%#]+)', '', regex=True)\n",
        "        df.text = df.text.replace('\\n', '', regex=True)\n",
        "        df.text = df.text.replace('\\r', '', regex=True)\n",
        "        df.text = df.text.replace('amp;', '', regex=True)\n",
        "        df.text = df.text.replace('RT', '', regex=True)\n",
        "        df.text = df.text.replace('FAV', '', regex=True)\n",
        "        df.text = df.text.map(replace_number_to_zero)\n",
        "        df = df.query('text != \" \"')\n",
        "        from_date = date.strftime('%Y-%m-%d')\n",
        "        from_date = date + timedelta(days = -6)\n",
        "        from_date = from_date.strftime('%Y-%m-%d')\n",
        "        to_date = date.strftime('%Y-%m-%d')\n",
        "\n",
        "        directory = directory1 + from_date + '_' + to_date + '_' + city + '.tsv'\n",
        "        print('Save: ' + directory)\n",
        "        df.to_csv(directory, sep='\\t', index=False, header=False)\n",
        "\n",
        "        directory = directory2 + from_date + '_' + to_date + '_' + city + '.tsv'\n",
        "        print('Save: ' + directory)\n",
        "        df2.to_csv(directory, sep='\\t', index=False, header=False)\n",
        "\n",
        "        print('Wait 4 seconds')\n",
        "        time.sleep(4)\n",
        "        # Initialize the Data Frame on day 7\n",
        "        df = pandas.DataFrame(columns=columns)\n",
        "        df2 = pandas.DataFrame(columns=columns2)\n",
        "        # Initialize the counter on day 7\n",
        "        i = 0\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "-La7aGxXYcL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ARkCU1HCeGMT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}