{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTNe5UF6oD6s0Rlk53FCb0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RyuichiSaito1/covid19-twitter-usa-restoring/blob/main/prepare_training_and_test_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coDpaFq_hR-z"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# 1. Read TSV file from a specific directory in Google Drive using read_table\n",
        "file_path = '/content/drive/MyDrive/covid-twitter-usa-normal/data/training_data/gpt-3.5/data_2021_shuffle_majority_vote.tsv'\n",
        "data = pd.read_table(file_path, names=['content', 'label'], dtype='object', engine='python')\n",
        "\n",
        "# 2. Shuffle the loaded data\n",
        "shuffled_data = shuffle(data)\n",
        "\n",
        "# 3. Split the data into the first 1,800 records, the next 400 records, and the rest\n",
        "training_data = shuffled_data[:1800]\n",
        "validation_data = shuffled_data[1800:2400]\n",
        "test_data = shuffled_data[2400:]\n",
        "\n",
        "# 4. Save the split data\n",
        "training_data.to_csv('/content/drive/MyDrive/covid-twitter-usa-normal/data/training_data/gpt-3.5/training_data_2021_shuffle_majority_vote_gpt3.5.tsv', sep='\\t', index=False)\n",
        "validation_data.to_csv('/content/drive/MyDrive/covid-twitter-usa-normal/data/training_data/gpt-3.5/validation_data_2021_shuffle_majority_vote_gpt3.5.tsv', sep='\\t', index=False)\n",
        "test_data.to_csv('/content/drive/MyDrive/covid-twitter-usa-normal/data/training_data/gpt-3.5/test_data_2021_shuffle_majority_vote_gpt3.5.tsv', sep='\\t', index=False)\n",
        "\n",
        "# 5. Print the saved file names and the number of entries\n",
        "print(\"Training Data: training_data_2021_shuffle_majority_vote_gpt3.5.tsv -\", len(training_data), \"entries\")\n",
        "print(\"Validation Data: validation_data_2021_shuffle_majority_vote_gpt3.5.tsv -\", len(validation_data), \"entries\")\n",
        "print(\"Test Data: test_data_2021_shuffle_majority_vote_gpt3.5.tsv -\", len(test_data), \"entries\")\n"
      ],
      "metadata": {
        "id": "POLP2XkdhUkP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}